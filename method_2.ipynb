{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "dual_2",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "import librosa"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T05:41:15.511403Z",
          "iopub.execute_input": "2025-04-17T05:41:15.511912Z",
          "iopub.status.idle": "2025-04-17T05:41:18.226252Z",
          "shell.execute_reply.started": "2025-04-17T05:41:15.511864Z",
          "shell.execute_reply": "2025-04-17T05:41:18.225396Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI6cmTvmRQuJ",
        "outputId": "42bc8811-8df1-42a0-c2b1-c7dbad8e615f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# 1. Vector Quantization Codec\n",
        "# ---------------------\n",
        "class ResidualVQ(nn.Module):\n",
        "    def __init__(self, num_semantic, num_acoustic, dim, mel_dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.project = nn.Linear(mel_dim, dim)\n",
        "        self.deproject = nn.Linear(dim, mel_dim)\n",
        "        self.quant1 = nn.Embedding(num_semantic, dim)\n",
        "        self.quant2 = nn.Embedding(num_acoustic, dim)\n",
        "\n",
        "    def forward(self, mel_frames):\n",
        "        # mel_frames: (B, T, mel_dim)\n",
        "        B, T, _ = mel_frames.size()\n",
        "        x = self.project(mel_frames)                    # (B, T, dim)\n",
        "        flat = x.view(-1, self.dim)                     # (B*T, dim)\n",
        "\n",
        "        # Semantic quantization\n",
        "        codebook1 = self.quant1.weight                   # (N1, dim)\n",
        "        d1 = (flat.pow(2).sum(1, keepdim=True)\n",
        "              + codebook1.pow(2).sum(1)\n",
        "              - 2 * flat @ codebook1.t())              # (B*T, N1)\n",
        "        idx1 = d1.argmin(1)                             # (B*T,)\n",
        "        quant1 = self.quant1(idx1).view(B, T, self.dim)\n",
        "\n",
        "        # Acoustic (residual) quantization\n",
        "        residual = flat - quant1.view(-1, self.dim)     # (B*T, dim)\n",
        "        codebook2 = self.quant2.weight                   # (N2, dim)\n",
        "        d2 = (residual.pow(2).sum(1, keepdim=True)\n",
        "              + codebook2.pow(2).sum(1)\n",
        "              - 2 * residual @ codebook2.t())          # (B*T, N2)\n",
        "        idx2 = d2.argmin(1)                             # (B*T,)\n",
        "        quant2 = self.quant2(idx2).view(B, T, self.dim)\n",
        "\n",
        "        return idx1.view(B, T), idx2.view(B, T)\n",
        "\n",
        "    def decode(self, sem_idxs, ac_idxs):\n",
        "        # sem_idxs, ac_idxs: (B, T)\n",
        "        sem_emb = self.quant1(sem_idxs)                  # (B, T, dim)\n",
        "        ac_emb = self.quant2(ac_idxs)                    # (B, T, dim)\n",
        "        x = sem_emb + ac_emb                             # (B, T, dim)\n",
        "        mel_recon = self.deproject(x)                    # (B, T, mel_dim)\n",
        "        return mel_recon\n",
        "\n",
        "# ---------------------\n",
        "# 2. Transformer Modules\n",
        "# ---------------------\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dim_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_ff),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_ff, d_model)\n",
        "        )\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T, d_model)\n",
        "        y, _ = self.attn(x, x, x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ff(x)\n",
        "        return self.ln2(x + y)\n",
        "\n",
        "class TemporalTransformer(nn.Module):\n",
        "    def __init__(self, d_model=512, n_heads=8, n_layers=6):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([TransformerBlock(d_model, n_heads) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, token_history):\n",
        "        # token_history: (B, T, d_model)\n",
        "        x = token_history\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x  # (B, T, d_model)\n",
        "\n",
        "class DepthTransformer(nn.Module):\n",
        "    def __init__(self, d_model, num_semantic, num_acoustic):\n",
        "        super().__init__()\n",
        "        self.to_semantic = nn.Linear(d_model, num_semantic)\n",
        "        self.to_acoustic = nn.Linear(d_model, num_acoustic)\n",
        "\n",
        "    def forward(self, z_t):\n",
        "        # z_t: (B, d_model)\n",
        "        sem_logits = self.to_semantic(z_t)\n",
        "        ac_logits = self.to_acoustic(z_t)\n",
        "        return sem_logits, ac_logits\n",
        "\n",
        "# ---------------------\n",
        "# 3. RQ‑Tacotron Model\n",
        "# ---------------------\n",
        "class RQTacotron(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embed_dim,\n",
        "        encoder_hidden,\n",
        "        d_model,\n",
        "        num_semantic,\n",
        "        num_acoustic,\n",
        "        mel_dim=80\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # Text Encoder (LSTM)\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.encoder = nn.LSTM(embed_dim, encoder_hidden, batch_first=True, bidirectional=True)\n",
        "        self.enc_proj = nn.Linear(2*encoder_hidden, d_model)\n",
        "\n",
        "        # VQ codec\n",
        "        self.vq = ResidualVQ(num_semantic, num_acoustic, d_model, mel_dim)\n",
        "\n",
        "        # Streams\n",
        "        self.sem_emb = nn.Embedding(num_semantic, d_model)\n",
        "        self.ac_emb = nn.Embedding(num_acoustic, d_model)\n",
        "\n",
        "        # Transformers\n",
        "        self.temporal = TemporalTransformer(d_model)\n",
        "        self.depth = DepthTransformer(d_model, num_semantic, num_acoustic)\n",
        "\n",
        "        # Vocoder\n",
        "        bundle = torchaudio.pipelines.TACOTRON2_WAVERNN_PHONE_LJSPEECH\n",
        "        self.vocoder = bundle.get_vocoder()\n",
        "\n",
        "    def forward(self, text_ids, sem_targets=None, ac_targets=None, max_steps=None):\n",
        "        # text_ids: (B, T_text)\n",
        "        B = text_ids.size(0)\n",
        "        device = text_ids.device\n",
        "\n",
        "        # Encode text → context\n",
        "        x = self.embedding(text_ids)\n",
        "        enc_out, _ = self.encoder(x)\n",
        "        ctx = self.enc_proj(enc_out)  # (B, T_text, d_model)\n",
        "\n",
        "        # Prepare histories\n",
        "        sem_history_emb = torch.zeros(B, 0, self.enc_proj.out_features, device=device)\n",
        "        ac_history_emb = torch.zeros(B, 0, self.enc_proj.out_features, device=device)\n",
        "\n",
        "        # Determine steps\n",
        "        if sem_targets is not None:\n",
        "            T = sem_targets.size(1)\n",
        "        else:\n",
        "            T = max_steps\n",
        "\n",
        "        loss_sem = 0.0\n",
        "        loss_ac = 0.0\n",
        "        ce_loss = nn.CrossEntropyLoss()\n",
        "        sem_logits_prev, ac_logits_prev = None, None\n",
        "\n",
        "        sem_preds = []\n",
        "        ac_preds = []\n",
        "\n",
        "        for t in range(T):\n",
        "            # Build full history sequence\n",
        "            history = torch.cat([ctx, sem_history_emb, ac_history_emb], dim=1)\n",
        "            # Compute context vector for this step\n",
        "            z_seq = self.temporal(history)\n",
        "            z_t = z_seq[:, -1, :]\n",
        "\n",
        "            # Depth predictions\n",
        "            sem_logits, ac_logits = self.depth(z_t)\n",
        "\n",
        "            if sem_targets is not None:\n",
        "                # Training: accumulate semantic loss\n",
        "                loss_sem += ce_loss(sem_logits, sem_targets[:, t])\n",
        "                # Acoustic loss delayed by one step\n",
        "                if ac_logits_prev is not None:\n",
        "                    loss_ac += ce_loss(ac_logits_prev, ac_targets[:, t-1])\n",
        "            else:\n",
        "                # Inference: sample or argmax\n",
        "                sem_idx = torch.argmax(sem_logits, dim=-1)\n",
        "                sem_preds.append(sem_idx)\n",
        "                if ac_logits_prev is not None:\n",
        "                    ac_idx = torch.argmax(ac_logits_prev, dim=-1)\n",
        "                    ac_preds.append(ac_idx)\n",
        "\n",
        "            # Update histories\n",
        "            if sem_targets is not None:\n",
        "                sem_idx = sem_targets[:, t]\n",
        "            sem_emb_t = self.sem_emb(sem_idx).unsqueeze(1)  # (B,1,d_model)\n",
        "            sem_history_emb = torch.cat([sem_history_emb, sem_emb_t], dim=1)\n",
        "\n",
        "            ac_logits_prev = ac_logits\n",
        "            if ac_targets is not None and t > 0:\n",
        "                ac_idx = ac_targets[:, t-1]\n",
        "                ac_emb_t = self.ac_emb(ac_idx).unsqueeze(1)\n",
        "                ac_history_emb = torch.cat([ac_history_emb, ac_emb_t], dim=1)\n",
        "\n",
        "        # Final acoustic for last step\n",
        "        if sem_targets is None:\n",
        "            # append last acoustic prediction\n",
        "            ac_idx = torch.argmax(ac_logits_prev, dim=-1)\n",
        "            ac_preds.append(ac_idx)\n",
        "\n",
        "        if sem_targets is not None:\n",
        "            return {\n",
        "                'sem_loss': loss_sem / T,\n",
        "                'ac_loss': loss_ac / max(1, T-1)\n",
        "            }\n",
        "        else:\n",
        "            sem_seq = torch.stack(sem_preds, dim=1)\n",
        "            ac_seq = torch.stack(ac_preds, dim=1)\n",
        "            return sem_seq, ac_seq\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, text, max_steps=200):\n",
        "        self.eval()\n",
        "        text_ids = TextProcessor()(text).unsqueeze(0).to(next(self.parameters()).device)\n",
        "        sem_seq, ac_seq = self.forward(text_ids, sem_targets=None, ac_targets=None, max_steps=max_steps)\n",
        "\n",
        "        # Decode to mel\n",
        "        mel = self.vq.decode(sem_seq, ac_seq)\n",
        "        # Vocoder to waveform\n",
        "        audio = self.vocoder(mel.transpose(1, 2))\n",
        "        return audio[0]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T05:41:18.2276Z",
          "iopub.execute_input": "2025-04-17T05:41:18.228082Z",
          "iopub.status.idle": "2025-04-17T05:41:18.250161Z",
          "shell.execute_reply.started": "2025-04-17T05:41:18.22806Z",
          "shell.execute_reply": "2025-04-17T05:41:18.249462Z"
        },
        "id": "oPzxVVHIRQuL"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# 4. Dataset & Training Loop\n",
        "# ---------------------\n",
        "class TextProcessor():\n",
        "    def __init__(self):\n",
        "        self.char_to_id = {c: i for i, c in enumerate(\"abcdefghijklmnopqrstuvwxyz '.,?!\")}\n",
        "    def __call__(self, text):\n",
        "        ids = [self.char_to_id[c] for c in text.lower() if c in self.char_to_id]\n",
        "        return torch.LongTensor(ids)\n",
        "\n",
        "class LJSpeechDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.dataset = load_dataset(\"lj_speech\", split=\"train\")\n",
        "        self.text_processor = TextProcessor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        wav, sr = torchaudio.load(item['file'])\n",
        "        wav = torchaudio.functional.resample(wav, sr, 22050)[0].numpy()\n",
        "        mel = librosa.feature.melspectrogram(\n",
        "            y=wav, sr=22050, n_fft=1024, hop_length=256, n_mels=80\n",
        "        ).T  # (T,80)\n",
        "        text_ids = self.text_processor(item['normalized_text'])\n",
        "        return text_ids, torch.FloatTensor(mel)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    texts, mels = zip(*batch)\n",
        "    texts_padded = nn.utils.rnn.pad_sequence(texts, batch_first=True)\n",
        "    mels_padded = nn.utils.rnn.pad_sequence(mels, batch_first=True)\n",
        "    return texts_padded, mels_padded"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T05:41:18.250824Z",
          "iopub.execute_input": "2025-04-17T05:41:18.251107Z",
          "iopub.status.idle": "2025-04-17T05:41:18.266248Z",
          "shell.execute_reply.started": "2025-04-17T05:41:18.25108Z",
          "shell.execute_reply": "2025-04-17T05:41:18.26557Z"
        },
        "id": "8Uq7zrlYRQuM"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = LJSpeechDataset()\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T05:41:23.315507Z",
          "iopub.execute_input": "2025-04-17T05:41:23.31608Z",
          "iopub.status.idle": "2025-04-17T05:41:24.577573Z",
          "shell.execute_reply.started": "2025-04-17T05:41:23.31605Z",
          "shell.execute_reply": "2025-04-17T05:41:24.576949Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8MG4w53RQuM",
        "outputId": "3c0746b6-b3ba-4fa0-afe7-dca1d61f6e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Hyperparams\n",
        "vocab_size = len(TextProcessor().char_to_id)\n",
        "model = RQTacotron(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=16,\n",
        "    encoder_hidden=16,\n",
        "    d_model=32,\n",
        "    num_semantic=32,\n",
        "    num_acoustic=32,\n",
        "    mel_dim=80\n",
        ").to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T05:41:26.56855Z",
          "iopub.execute_input": "2025-04-17T05:41:26.568997Z",
          "iopub.status.idle": "2025-04-17T05:41:28.064687Z",
          "shell.execute_reply.started": "2025-04-17T05:41:26.568973Z",
          "shell.execute_reply": "2025-04-17T05:41:28.06395Z"
        },
        "id": "1bAVPgHeRQuM"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for epoch in range(1, 101):\n",
        "    for texts, mels in loader:\n",
        "        texts, mels = texts.to(device), mels.to(device)\n",
        "        # Quantize targets\n",
        "        sem_toks, ac_toks = model.vq(mels)\n",
        "\n",
        "        # Forward + losses\n",
        "        losses = model(texts, sem_targets=sem_toks, ac_targets=ac_toks)\n",
        "        loss = 100 * losses['sem_loss'] + 1 * losses['ac_loss']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "        break\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T05:41:30.499988Z",
          "iopub.execute_input": "2025-04-17T05:41:30.500482Z",
          "iopub.status.idle": "2025-04-17T05:41:33.370246Z",
          "shell.execute_reply.started": "2025-04-17T05:41:30.500457Z",
          "shell.execute_reply": "2025-04-17T05:41:33.369092Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "wCFd_4e3RQuN",
        "outputId": "c2e2bf28-04c1-48ba-afb7-d04811b6af4d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 6.12 MiB is free. Process 26568 has 14.73 GiB memory in use. Of the allocated memory 14.00 GiB is allocated by PyTorch, and 618.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-585f0a9aae57>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Forward + losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msem_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mac_toks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sem_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ac_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-72a734b0d380>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text_ids, sem_targets, ac_targets, max_steps)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem_history_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac_history_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m# Compute context vector for this step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mz_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-72a734b0d380>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_history)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# (B, T, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-72a734b0d380>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# x: (B, T, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6373\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6374\u001b[0;31m         \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6376\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 6.12 MiB is free. Process 26568 has 14.73 GiB memory in use. Of the allocated memory 14.00 GiB is allocated by PyTorch, and 618.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference example\n",
        "audio = model.generate(\"Hello world, streaming TTS!\")\n",
        "torchaudio.save(\"output_stream.wav\", audio.cpu(), 22050)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "snO1DPz_RQuN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import IPython\n",
        "\n",
        "path = \"output_stream.wav\"\n",
        "IPython.display.Audio(path)"
      ],
      "metadata": {
        "trusted": true,
        "id": "vkUgkcJWRQuN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "DslDGRu_RQuN"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}